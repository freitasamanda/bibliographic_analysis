Authors,Author Full Names,Publication Year,Source Title,Language,Document Type,Conference Title,Author Keywords,Keywords Plus,Article Title,Abstract,TEMA,MÉTODO,Affiliations,"Times Cited, WoS Core","Times Cited, All Databases",Publisher,Publisher City,Journal Abbreviation,DOI,DOI Link,WoS Categories,Web of Science Index,Research Areas,,id,label,cluster,assunto central do paper TÍTULO,weight<Citations>
"Heidari, M; Jones, JH","Heidari, Maryam; Jones, James H.",2020,"2020 11TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON)",English,Proceedings Paper,"11th IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference (UEMCON)",Bot detection; Natural language processing; Neural Network; Social media,,Using BERT to Extract Topic-Independent Sentiment Features for Social Media Bot Detection,"Millions of online posts about different topics and products are shared on popular social media platforms. One use of this content is to provide crowd-sourced information about a specific topic, event, or product. However, this use raises an important question: what percentage of the information available through these services is trustworthy? In particular, might some of this information be generated by a machine, i.e., a bot instead of a human? Bots can be, and often are, purposely designed to generate enough volume to skew an apparent trend or position on a topic, yet the consumer of such content cannot easily distinguish a bot post from a human post. This paper introduces a new model that uses Bidirectional Encoder Representations from Transformers (Google Bert) for sentiment classification of tweets to identify topic-independent features for the social media bot detection model. Using a Natural Language Processing approach to derive topic-independent features for the new bot detection model distinguishes this work from previous bot detection models. We achieve 94% accuracy classifying the contents of Cresci data set [1] as generated by a bot or a human, where the most accurate prior work achieved an accuracy of 92%.",,,,24,24,IEEE,NEW YORK,,,,,"Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science; Engineering; Telecommunications,36,heidari (2020a),1,detecting bots (general),24
"Alothali, E; Zaki, N; Mohamed, EA; Alashwal, H","Alothali, Eiman; Zaki, Nazar; Mohamed, Elfadil A.; Alashwal, Hany",2018,PROCEEDINGS OF THE 2018 13TH INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION TECHNOLOGY (IIT),English,Proceedings Paper,13th International Conference on Innovations in Information Technology (IIT),Social Bots; Twitter; Detection; Sybil,MALICIOUS ACCOUNTS; SPAM DETECTION,Detecting Social Bots on Twitter: A Literature Review,"Due to the exponential growth in the popularity of online social networks (OSNs), such as Twitter and Facebook, the number of machine accounts that are designed to mimic human users has increased. Social bots accounts (Sybils) have become more sophisticated and deceptive in their efforts to replicate the behaviors of normal accounts. As such, there is a distinct need for the research community to develop technologies that can detect social bots. This paper presents a review of the recent techniques that have emerged that are designed to differentiate between social bot account and human accounts. We limit the analysis to the detection of social bots on the Twitter social media platform. We review the various detection schemes that are currently in use and examine common aspects such as the classifier, datasets, and selected features employed. We also compare the evaluation techniques that are employed to validate the classifiers. Finally, we highlight the challenges that remain in the domain of social bot detection and consider future directions for research efforts that are designed to address this problem.",,,,26,26,IEEE,NEW YORK,IEEE INT CONF INNOV,,,,"Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Electrical & Electronic",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science; Engineering,189,alothali (2018),1,detecting bots (general),26
"Gilani, Z; Wang, L; Crowcroft, J; Almeida, M; Farahbakhsh, R","Gilani, Zafar; Wang, Liang; Crowcroft, Jon; Almeida, Mario; Farahbakhsh, Reza",2016,PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION),English,Proceedings Paper,25th International Conference on World Wide Web (WWW),information dissemination; bot analyser; content analysis,,Stweeler: A Framework for Twitter Bot Analysis,"The WWW has seen a massive growth in variety and usage of OSNs. The rising population of users on Twitter and its open nature has made it an ideal platform for various kinds of opportunistic pursuits, such as news and emergency communication, business promotion, political campaigning, spamming and spreading malicious content. Most of these opportunistic pursuits are exploited through automated programs, known as bots. In this study we propose a framework (Stweeler) to study bot impact and influence on Twitter from systems and social media perspectives.",,,,27,27,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/2872518.2889360,http://dx.doi.org/10.1145/2872518.2889360,"Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,97,gilani (2016),1,detecting bots (general),27
"Cai, CY; Li, LJ; Zeng, D","Cai, Chiyu; Li, Linjing; Zeng, Daniel",2017,2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI),English,Proceedings Paper,15th IEEE International Conference on Intelligence and Security Informatics - Security and Big Data (ISI),,,Behavior Enhanced Deep Bot Detection in Social Media,"Social bots are regarded as the most common kind of malwares in social platform. They can produce fake messages, spread rumours, and even manipulate public opinions. Recently, massive social bots are created and widely spread in social platform, they bring negative effects to public and netizen security. Bot detection aims to distinguish bots from human and it catches more and more attentions in recent years. In this paper, we propose a behavior enhanced deep model (BeDM) for bot detection. The proposed model regards user content as temporal text data instead of plain text to extract latent temporal patterns. Moreover, BeDM fuses content information and behavior information using deep learning method. To the best of our knowledge, this is the first trial that applies deep neural network in bot detection. Experiments on real world dataset collected from Twitter also demonstrate the effectiveness of our proposed model.",,,,31,31,IEEE,NEW YORK,,,,"Computer Science, Theory & Methods; Engineering, Electrical & Electronic",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science; Engineering,,208,cai (2017b),1,detecting bots (general),31
"Van Der Walt, E; Eloff, J","Van Der Walt, Estee; Eloff, Jan",2018,IEEE ACCESS,English,Article,,Big data; bots; data science; fake accounts; fake identities; identity deception; social media; veracity,ONLINE DECEPTION; MOTIVATION,Using Machine Learning to Detect Fake Identities: Bots vs Humans,"There are a growing number of people who hold accounts on social media platforms (SMPs) but hide their identity for malicious purposes. Unfortunately, very little research has been done to date to detect fake identities created by humans, especially so on SMPs. In contrast, many examples exist of cases where fake accounts created by bots or computers have been detected successfully using machine learning models. In the case of bots these machine learning models were dependent on employing engineered features, such as the friend-to-followers ratio.'' These features were engineered from attributes, such as friend-count'' and follower-count,'' which are directly available in the account profiles on SMPs. The research discussed in this paper applies these same engineered features to a set of fake human accounts in the hope of advancing the successful detection of fake identities created by humans on SMPs.",,,,45,46,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,PISCATAWAY,IEEE ACCESS,10.1109/ACCESS.2018.2796018,http://dx.doi.org/10.1109/ACCESS.2018.2796018,"Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science; Engineering; Telecommunications,,124,van der walt (2018b),1,detecting bots (general),45
"Costa, AF; Yamaguchi, Y; Traina, AJM; Traina, C; Faloutsos, C","Costa, Alceu Ferraz; Yamaguchi, Yuto; Machado Traina, Agma Juci; Traina, Caetano, Jr.; Faloutsos, Christos",2015,KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING,English,Proceedings Paper,21st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),Social Media; Time-Series; User Behavior; Generative Model,HEAVY TAILS,RSC: Mining and Modeling Temporal Activity in Social Media,"Can we identify patterns of temporal activities caused by human communications in social media? Is it possible to model these patterns and tell if a user is a human or a bot based only on the timing of their postings? Social media services allow users to make postings, generating large datasets of human activity time-stamps. In this paper we analyze time-stamp data from social media services and find that the distribution of postings inter-arrival times (IAT) is characterized by four patterns: (i) positive correlation between consecutive IATs, (ii) heavy tails, (iii) periodic spikes and (iv) bimodal distribution. Based on our findings, we propose Rest-Sleep-and-Comment (RSC), a generative model that is able to match all four discovered patterns. We demonstrate the utility of RSC by showing that it can accurately fit real time-stamp data from Reddit and Twitter. We also show that RSC can be used to spot outliers and detect users with non-human behavior, such as bots. We validate RSC using real data consisting of over 35 million postings from Twitter and Reddit. RSC consistently provides a better fit to real data and clearly outperform existing models for human dynamics. RSC was also able to detect bots with a precision higher than 94%.",,,,46,47,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/2783258.2783294,http://dx.doi.org/10.1145/2783258.2783294,"Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,204,costa (2015),1,detecting bots (general),46
"Morstatter, F; Wu, L; Nazer, TH; Carley, KM; Liu, H","Morstatter, Fred; Wu, Liang; Nazer, Tahora H.; Carley, Kathleen M.; Liu, Huan",2016,PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016,English,Proceedings Paper,8th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),,,A New Approach to Bot Detection: Striking the Balance Between Precision and Recall,"The presence of bots has been felt in many aspects of social media. Twitter, one example of social media, has especially felt the impact, with bots accounting for a large portion of its users. These bots have been used for malicious tasks such as spreading false information about political candidates and inflating the perceived popularity of celebrities. Furthermore, these bots can change the results of common analyses performed on social media. It is important that researchers and practitioners have tools in their arsenal to remove them. Approaches exist to remove bots, however they focus on precision to evaluate their model at the cost of recall. This means that while these approaches are almost always correct in the bots they delete, they ultimately delete very few, thus many bots remain. We propose a model which increases the recall in detecting bots, allowing a researcher to delete more bots. We evaluate our model on two real-world social media datasets and show that our detection algorithm removes more bots from a dataset than current approaches.",,,,74,76,IEEE,NEW YORK,,,,"Computer Science, Information Systems; Communication; Computer Science, Interdisciplinary Applications; Social Sciences, Interdisciplinary",Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index- Social Science &amp; Humanities (CPCI-SSH),Computer Science; Communication; Social Sciences - Other Topics,,58,morstatter (2016a),1,detecting bots (general),74
"Lokot, T; Diakopoulos, N","Lokot, Tetyana; Diakopoulos, Nicholas",2016,DIGITAL JOURNALISM,English,Article,,algorithmic journalism; automated journalism; bots; computational journalism; news bots; social media; Twitter,,Automating news and information dissemination on Twitter,"So-called robot journalism represents a shift towards the automation of journalistic tasks related to news reporting, writing, curation, and even data analysis. In this paper, we consider the extension of robot journalism to the domain of social platforms and study the use of news bots-automated accounts that participate in news and information dissemination on social networks. Such bots present an intriguing development opportunity for news organizations and journalists. In particular, we analyze a sample of existing news bot accounts on Twitter to understand how news bots are currently being used and to examine how using automation and algorithms may change the modern media environment. Based on our analysis, we propose a typology of news bots in the form of a design and editorial decision space that can guide designers in defining the intent, utility, and functionality of future bots. The proposed design space highlights the limits of news bots (e.g., automated commentary and opinion, algorithmic transparency and accountability) and areas where news bots may enable innovation, such as niche and local news.",,,,86,87,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD",ABINGDON,DIGIT JOURNAL,10.1080/21670811.2015.1081822,http://dx.doi.org/10.1080/21670811.2015.1081822,Communication,Social Science Citation Index (SSCI),Communication,,75,lokot (2016),1,detecting bots (general),86
"Murthy, D; Powell, AB; Tinati, R; Anstead, N; Carr, L; Halford, SJ; Weal, M","Murthy, Dhiraj; Powell, Alison B.; Tinati, Ramine; Anstead, Nick; Carr, Leslie; Halford, Susan J.; Weal, Mark",2016,INTERNATIONAL JOURNAL OF COMMUNICATION,English,Article,,bots; political communication; capital; moral panics; experimental methods,TWITTER,Bots and Political Influence: A Sociotechnical Investigation of Social Network Capital,"This study explains how bots interact with human users and influence conversational networks on Twitter. We analyze a high-stakes political environment, the UK general election of May 2015, asking human volunteers to tweet from purpose-made Twitter accounts-half of which had bots attached-during three events: the last Prime Minister's Question Time before Parliament was dissolved (#PMQs), the first leadership interviews of the campaign (#BattleForNumber10), and the BBC Question Time broadcast of the same evening (#BBCQT). Based on previous work, our expectation was that our intervention would make a significant difference to the evolving network, but we found that the bots we used had very little effect on the conversation network at all. There are economic, social, and temporal factors that impact how a user of bots can influence political conversations. Future research needs to account for these forms of capital when assessing the impact of bots on political discussions.",,,,24,28,USC ANNENBERG PRESS,LOS ANGELES,INT J COMMUN-US,,,Communication,Social Science Citation Index (SSCI),Communication,,51,murthy (2016),2,monitoring bots (politics),24
"Sanovich, S; Stukal, D; Tucker, JA","Sanovich, Sergey; Stukal, Denis; Tucker, Joshua A.",2018,COMPARATIVE POLITICS,English,Article,,,SOCIAL MEDIA; LIBERATION; INTERNET; TWITTER,Turning the Virtual Tables: Government Strategies for Addressing Online Opposition with an Application to Russia,"We introduce a novel classification of strategies employed by autocrats to combat online opposition generally, and opposition on social media in particular. Our classification distinguishes both online from offline responses and censorship from engaging in opinion formation. For each of the three options offline action, technical restrictions on access to content, and online engagement we provide a detailed account for the evolution of Russian government strategy since 2000. To illustrate the feasibility of researching online engagement, we construct and assess tools for detecting the activity of political bots, or algorithmically controlled accounts, on Russian political Twitter, and test these methods on a large dataset of politically relevant Twitter data from Russia gathered over a year and a half.",,,,26,28,SHERIDAN PRESS,HANOVER,COMP POLIT,10.5129/001041518822704890,http://dx.doi.org/10.5129/001041518822704890,Political Science,Social Science Citation Index (SSCI),Government & Law,,129,sanovich (2018),2,evaluating impact of bots (politics),26
"Alsaleh, M; Alarifi, A; Al-Salman, A; AlFayez, M; Almuhaysin, A","Alsaleh, Mansour; Alarifi, Abdulrahman; Al-Salman, AbdulMalik; AlFayez, Mohammed; Almuhaysin, Abdulmajeed",2014,2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA),English,Proceedings Paper,13th International Conference on Machine Learning and Applications (ICMLA),Social networks; Sybil account; Fake user accounts; Twitter; Web spam; Content spam; Spamdexing,,TSD: Detecting Sybil Accounts in Twitter,"Fake identities and user accounts (also called Sybils) in online communities represent today a treasure for adversaries to spread fake product reviews, malware and spam on social networks, and astroturf political campaigns. State-of-the-art in the defense mechanisms includes Automated Turing Tests (ATTs such as CAPTCHAs) and graph-based Sybil detectors. Sybil detectors in social networks leverage the assumption that Sybils will find it hard to befriend real users which leads to Sybils being connected to each other forming strongly connected sub graphs that can be detected using graph theory. However, the large majority of Sybils are in fact successful in integrating themselves into real user communities (such as the case in Twitter and Facebook). In this paper, we first study and compare the current detection mechanisms of Sybil accounts. We also explore various types of Twitter Sybil accounts detection features with the objective of building an effective and practical classifier. In order to build and evaluate our classifier, we collect and manually label a dataset of twitter accounts, including human users, bots, and hybrid (i.e., tweets are posted by both human and bots). We believe this Twitter Sybils corpus will help researchers in conducting sound measurement studies. We also develop a browser plug-in (that we call Twitter Sybils Detector or TSD for short) that utilizes our classifier and warns the user about possible Sybil accounts before accessing them, upon clicking on a Twitter account.",,,,29,29,IEEE,NEW YORK,,10.1109/ICMLA.2014.81,http://dx.doi.org/10.1109/ICMLA.2014.81,"Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,400,alsaleh (2014),2,detecting bots (general),29
"Alarifi, A; Alsaleh, M; Al-Salman, A","Alarifi, Abdulrahman; Alsaleh, Mansour; Al-Salman, AbdulMalik",2016,INFORMATION SCIENCES,English,Article,,Content spam; Fake user account; Social network; Sybil account; Twitter; Web spam,,Twitter turing test: Identifying social machines,"Many machine-controlled Twitter accounts (also called Sybils) are created each day to provide services, flood out messages for astroturf political campaigns, write fake product reviews, or produce an underground marketplace for purchasing Twitter followers, retweets, or URL advertisements. In addition, fake identities and user accounts in online communities are resources used by adversaries to spread malware, spam, and harmful links over social networks. In social networks, Sybil detectors rely on the assumption that Sybils will find it harder to befriend real users; thus, Sybils that are connected to. each other form strongly connected subgraphs, which can be detected using the graph theory. However, a majority of Sybils have actually successfully integrated themselves into real social media user communities (such as Twitter and Facebook). In this study, we compared the current methods used for detecting Sybil accounts. We also explored the detection features of various types of Twitter Sybil accounts in order to build an effective and practical classifier. To evaluate our classifier, we collected and manually labeled a dataset of Twitter accounts, including human users, bots, and hybrids (i.e., tweets posted by both human and bots). We consider that this Twitter Sybils corpus will help researchers to conduct high-quality measurement studies. We also developed a browser plug-in, which utilizes our classifier and warns the user about possible Sybil accounts before accessing or following them after clicking on a Twitter account. (C) 2016 Elsevier Inc. All rights reserved.",,,,34,35,ELSEVIER SCIENCE INC,NEW YORK,INFORM SCIENCES,10.1016/j.ins.2016.08.036,http://dx.doi.org/10.1016/j.ins.2016.08.036,"Computer Science, Information Systems",Science Citation Index Expanded (SCI-EXPANDED),Computer Science,,136,alarifi (2016),2,detecting bots (general),34
"Clark, EM; Williams, JR; Jones, CA; Galbraith, RA; Danforth, CM; Dodds, PS","Clark, Eric M.; Williams, Jake Ryland; Jones, Chris A.; Galbraith, Richard A.; Danforth, Christopher M.; Dodds, Peter Sheridan",2016,JOURNAL OF COMPUTATIONAL SCIENCE,English,Article,,,,Sifting robotic from organic text: A natural language approach for detecting automation on Twitter,"Twitter, a popular social media outlet, has evolved into a vast source of linguistic data, rich with opinion, sentiment, and discussion. Due to the increasing popularity of Twitter, its perceived potential for exerting social influence has led to the rise of a diverse community of automatons, commonly referred to as bots. These inorganic and semi-organic Twitter entities can range from the benevolent (e.g., weather-update bots, help-wanted-alert bots) to the malevolent (e.g., spamming messages, advertisements, or radical opinions). Existing detection algorithms typically leverage metadata (time between tweets, number of followers, etc.) to identify robotic accounts. Here, we present a powerful classification scheme that exclusively uses the natural language text from organic users to provide a criterion for identifying accounts posting automated messages. Since the classifier operates on text alone, it is flexible and may be applied to any textual data beyond the Twittersphere. (C) 2015 Elsevier B.V. All rights reserved.",,,,46,47,ELSEVIER SCIENCE BV,AMSTERDAM,J COMPUT SCI-NETH,10.1016/j.jocs.2015.11.002,http://dx.doi.org/10.1016/j.jocs.2015.11.002,"Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods",Science Citation Index Expanded (SCI-EXPANDED),Computer Science,,220,clark (2016),2,detecting bots (general),46
"Stukal, D; Sanovich, S; Bonneau, R; Tucker, JA","Stukal, Denis; Sanovich, Sergey; Bonneau, Richard; Tucker, Joshua A.",2017,BIG DATA,English,Article,,bot detection; ensemble methods; machine learning; Russia; Twitter,,Detecting Bots on Russian Political Twitter,"Automated and semiautomated Twitter accounts, bots, have recently gained significant public attention due to their potential interference in the political realm. In this study, we develop a methodology for detecting bots on Twitter using an ensemble of classifiers and apply it to study bot activity within political discussions in the Russian Twittersphere. We focus on the interval from February 2014 to December 2015, an especially consequential period in Russian politics. Among accounts actively Tweeting about Russian politics, we find that on the majority of days, the proportion of Tweets produced by bots exceeds 50%. We reveal bot characteristics that distinguish them from humans in this corpus, and find that the software platform used for Tweeting is among the best predictors of bots. Finally, we find suggestive evidence that one prominent activity that bots were involved in on Russian political Twitter is the spread of news stories and promotion of media who produce them.",,,,53,54,"MARY ANN LIEBERT, INC",NEW ROCHELLE,BIG DATA-US,10.1089/big.2017.0038,http://dx.doi.org/10.1089/big.2017.0038,"Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods",Science Citation Index Expanded (SCI-EXPANDED),Computer Science,,90,stukal (2017),2,detecting bots (politics),53
"Chavoshi, N; Hamooni, H; Mueen, A","Chavoshi, Nikan; Hamooni, Hossein; Mueen, Abdullah",2016,2016 IEEE 16TH INTERNATIONAL CONFERENCE ON DATA MINING (ICDM),English,Proceedings Paper,16th IEEE International Conference on Data Mining (ICDM),,,DeBot: Twitter Bot Detection via Warped Correlation,"We develop a warped correlation finder to identify correlated user accounts in social media websites such as Twitter. The key observation is that humans cannot be highly synchronous for a long duration; thus, highly synchronous user accounts are most likely bots. Existing bot detection methods are mostly supervised, which requires a large amount of labeled data to train, and do not consider cross-user features. In contrast, our bot detection system works on activity correlation without requiring labeled data. We develop a novel lag-sensitive hashing technique to cluster user accounts into correlated sets in near real-time. Our method, named DeBot, detects thousands of hots per day with a 94% precision and generates reports online everyday. In September 2016, DeBot has accumulated about 544,868 unique hots in the previous one year. We compare our detection technique with per-user techniques and with Twitter's suspension system. We observe that some both can avoid Twitter's suspension mechanism and remain active for months, and, more alarmingly, we show that DeBot detects both at a rate higher than the rate Twitter is suspending them.",,,,91,91,IEEE,NEW YORK,IEEE DATA MINING,10.1109/ICDM.2016.86,http://dx.doi.org/10.1109/ICDM.2016.86,"Computer Science, Artificial Intelligence; Computer Science, Information Systems",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,274,chavoshi (2016),2,detecting bots (general),91
"Howard, PN; Woolley, S; Calo, R","Howard, Philip N.; Woolley, Samuel; Calo, Ryan",2018,JOURNAL OF INFORMATION TECHNOLOGY & POLITICS,English,Article,,Algorithms; social media; democracy; elections; communication law and policy; Federal Election Commission,TWITTER; MEDIA,"Algorithms, bots, and political communication in the US 2016 election: The challenge of automated political communication for election law and administration","Political communication is the process of putting information, technology, and media in the service of power. Increasingly, political actors are automating such processes, through algorithms that obscure motives and authors yet reach immense networks of people through personal ties among friends and family. Not all political algorithms are used for manipulation and social control however. So what are the primary ways in which algorithmic political communication-organized by automated scripts on social media-may undermine elections in democracies? In the US context, what specific elements of communication policy or election law might regulate the behavior of such bots, or the political actors who employ them? First, we describe computational propaganda and define political bots as automated scripts designed to manipulate public opinion. Second, we illustrate how political bots have been used to manipulate public opinion and explain how algorithms are an important new domain of analysis for scholars of political communication. Finally, we demonstrate how political bots are likely to interfere with political communication in the United States by allowing surreptitious campaign coordination, illegally soliciting either contributions or votes, or violating rules on disclosure.",,,,92,95,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD",ABINGDON,J INF TECHNOL POLITI,10.1080/19331681.2018.1448735,http://dx.doi.org/10.1080/19331681.2018.1448735,Communication; Political Science,Social Science Citation Index (SSCI),Communication; Government & Law,,45,howard (2018),2,evaluating impact of bots (politics),92
"Haustein, S; Bowman, TD; Holmberg, K; Tsou, A; Sugimoto, CR; Lariviere, V","Haustein, Stefanie; Bowman, Timothy D.; Holmberg, Kim; Tsou, Andrew; Sugimoto, Cassidy R.; Lariviere, Vincent",2016,JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY,English,Article,,information dissemination; scientometrics; preprints,CITATIONS; METRICS,Tweets as impact indicators: Examining the implications of automated bot accounts on Twitter,"This brief communication presents preliminary findings on automated Twitter accounts distributing links to scientific articles deposited on the preprint repository arXiv. It discusses the implication of the presence of such bots from the perspective of social media metrics (altmetrics), where mentions of scholarly documents on Twitter have been suggested as a means of measuring impact that is both broader and timelier than citations. Our results show that automated Twitter accounts create a considerable amount of tweets to scientific articles and that they behave differently than common social bots, which has critical implications for the use of raw tweet counts in research evaluation and assessment. We discuss some definitions of Twitter cyborgs and bots in scholarly communication and propose distinguishing between different levels of engagementthat is, differentiating between tweeting only bibliographic information to discussing or commenting on the content of a scientific work.",,,,111,116,WILEY,HOBOKEN,J ASSOC INF SCI TECH,10.1002/asi.23456,http://dx.doi.org/10.1002/asi.23456,"Computer Science, Information Systems; Information Science & Library Science",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science; Information Science & Library Science,,213,haustein (2016),2,monitoring bots (general),111
"Sayyadiharikandeh, M; Varol, O; Yang, KC; Flammini, A; Menczer, F","Sayyadiharikandeh, Mohsen; Varol, Onur; Yang, Kai-Cheng; Flammini, Alessandro; Menczer, Filippo",2020,CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT,English,Proceedings Paper,29th ACM International Conference on Information and Knowledge Management (CIKM),Social media; social bots; machine learning; cross-domain; recall,,Detection of Novel Social Bots by Ensembles of Specialized Classifiers,"Malicious actors create inauthentic social media accounts controlled in part by algorithms, known as social bots, to disseminate misinformation and agitate online discussion. While researchers have developed sophisticated methods to detect abuse, novel bots with diverse behaviors evade detection. We show that different types of bots are characterized by different behavioral features. As a result, supervised learning techniques suffer severe performance deterioration when attempting to detect behaviors not observed in the training data. Moreover, tuning these models to recognize novel bots requires retraining with a significant amount of new annotations, which are expensive to obtain. To address these issues, we propose a new supervised learning method that trains classifiers specialized for each class of bots and combines their decisions through the maximum rule. The ensemble of specialized classifiers (ESC) can better generalize, leading to an average improvement of 56% in F1 score for unseen accounts across datasets. Furthermore, novel bot behaviors are learned with fewer labeled examples during retraining. We deployed ESC in the newest version of Botometer, a popular tool to detect social bots in the wild, with a cross-validation AUC of 0.99.",,,,23,23,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/3340531.3412698,http://dx.doi.org/10.1145/3340531.3412698,"Computer Science, Information Systems; Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,72,sayyadiharikandeh (2020),3,detecting bots (general),23
"Yang, KC; Varol, O; Hui, PM; Menczer, F","Yang, Kai-Cheng; Varol, Onur; Hui, Pik-Mai; Menczer, Filippo",2020,"THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE",English,Proceedings Paper,34th AAAI Conference on Artificial Intelligence / 32nd Innovative Applications of Artificial Intelligence Conference / 10th AAAI Symposium on Educational Advances in Artificial Intelligence,,,Scalable and Generalizable Social Bot Detection through Data Selection,"Efficient and reliable social bot classification is crucial for detecting information manipulation on social media. Despite rapid development, state-of-the-art bot detection models still face generalization and scalability challenges, which greatly limit their applications. In this paper we propose a framework that uses minimal account metadata, enabling efficient analysis that scales up to handle the full stream of public tweets of Twitter in real time. To ensure model accuracy, we build a rich collection of labeled datasets for training and validation. We deploy a strict validation system so that model performance on unseen datasets is also optimized, in addition to traditional cross-validation. We find that strategically selecting a subset of training data yields better model accuracy and generalization than exhaustively training on all available data. Thanks to the simplicity of the proposed model, its logic can be interpreted to provide insights into social bot characteristics.",,,,44,44,ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE,PALO ALTO,AAAI CONF ARTIF INTE,,,"Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Education, Scientific Disciplines",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science; Education & Educational Research,,210,yang (2020),3,detecting bots (politics),44
"Keller, TR; Klinger, U","Keller, Tobias R.; Klinger, Ulrike",2019,POLITICAL COMMUNICATION,English,Article,,social bots; elections; Twitter; public sphere; Germany,POLITICAL COMMUNICATION; MEDIA,"Social Bots in Election Campaigns: Theoretical, Empirical, and Methodological Implications","Social bots mimic and potentially manipulate humans and their behaviours in social networks. The public sphere might be especially vulnerable to their impacts, which is why we first discuss their potential influence on the public sphere from a theoretical perspective. From an empirical perspective, we analyzed Twitter followers of seven German parties before (N = 638,674) and during (N = 838,026) the 2017 electoral campaigns regarding bot prevalence and activities. The results revealed that the share of social bots increased from 7.1% before to 9.9% during the election campaigns. The percentage of active social bots remained roughly the same. An analysis of the content distributed by both the most popular and the most active bots showed that they disseminate few political hashtags, and that almost none referred to German politics. We discuss the results against the background of normative traditions of public sphere theories and address the methodological challenges bots pose in political communication.",,,,47,47,TAYLOR & FRANCIS INC,PHILADELPHIA,POLIT COMMUN,10.1080/10584609.2018.1526238,http://dx.doi.org/10.1080/10584609.2018.1526238,Communication; Political Science,Social Science Citation Index (SSCI),Communication; Government & Law,,222,keller (2019),3,avaliando impacto de bots,47
"Yang, KC; Varol, O; Davis, CA; Ferrara, E; Flammini, A; Menczer, F","Yang, Kai-Cheng; Varol, Onur; Davis, Clayton A.; Ferrara, Emilio; Flammini, Alessandro; Menczer, Filippo",2019,HUMAN BEHAVIOR AND EMERGING TECHNOLOGIES,English,Article,,social influence; social media; social networking,INTERNET; NEWS,Arming the public with artificial intelligence to counter social bots,"The increased relevance of social media in our daily life has been accompanied by efforts to manipulate online conversations and opinions. Deceptive social bots-automated or semi-automated accounts designed to impersonate humans-have been successfully exploited for these kinds of abuse. Researchers have responded by developing artificial intelligence (AI) tools to arm the public in the fight against social bots. Here we review the literature on different types of bots, their impact, and detection methods. We use the case study of Botometer, a popular bot detection tool developed at Indiana University, to illustrate how people interact with AI countermeasures. A user experience survey suggests that bot detection has become an integral part of the social media experience for many users. However, barriers in interpreting the output of AI tools can lead to fundamental misunderstandings. The arms race between machine learning methods to develop sophisticated bots and effective countermeasures makes it necessary to update the training data and features of detection tools. We again use the Botometer case to illustrate both algorithmic and interpretability improvements of bot scores, designed to meet user expectations. We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.",,,,116,116,WILEY-HINDAWI,LONDON,HUM BEHAV EMERG TECH,10.1002/hbe2.115,http://dx.doi.org/10.1002/hbe2.115,"Psychology, Multidisciplinary",Emerging Sources Citation Index (ESCI),Psychology,,174,yang (2019b),3,evaluating impact of bots (politics),116
"Uyheng, J; Carley, KM","Uyheng, Joshua; Carley, Kathleen M.",2020,JOURNAL OF COMPUTATIONAL SOCIAL SCIENCE,English,Article,,Hate speech; Social cybersecurity; Bots; Information maneuvers; COVID-19,SPEECH; COMMUNICATION; TWITTER; RACISM; WORDS,Bots and online hate during the COVID-19 pandemic: case studies in the United States and the Philippines,"Online hate speech represents a serious problem exacerbated by the ongoing COVID-19 pandemic. Although often anchored in real-world social divisions, hate speech in cyberspace may also be fueled inorganically by inauthentic actors like social bots. This work presents and employs a methodological pipeline for assessing the links between hate speech and bot-driven activity through the lens of social cybersecurity. Using a combination of machine learning and network science tools, we empirically characterize Twitter conversations about the pandemic in the United States and the Philippines. Our integrated analysis reveals idiosyncratic relationships between bots and hate speech across datasets, highlighting different network dynamics of racially charged toxicity in the US and political conflicts in the Philippines. Most crucially, we discover that bot activity is linked to higher hate in both countries, especially in communities which are denser and more isolated from others. We discuss several insights for probing issues of online hate speech and coordinated disinformation, especially through a global approach to computational social science.",,,,22,22,SPRINGERNATURE,LONDON,J COMPUT SOC SCI,10.1007/s42001-020-00087-4,http://dx.doi.org/10.1007/s42001-020-00087-4,"Social Sciences, Mathematical Methods",Emerging Sources Citation Index (ESCI),Mathematical Methods In Social Sciences,,284,uyheng (2020),4,monitoring bots (politics),22
"Schafer, F; Evert, S; Heinrich, P","Schaefer, Fabian; Evert, Stefan; Heinrich, Philipp",2017,BIG DATA,English,Article,,Twitter; social bots; computational propaganda; internet right-wingers; Japan's 2014 general election; populism; near-duplicate detection,NEWS; COMMUNICATION; TWITTER; MEDIA,"Japan's 2014 General Election: Political Bots, Right-Wing Internet Activism, and Prime Minister Shinz Abe's Hidden Nationalist Agenda","In this article, we present results on the identification and behavioral analysis of social bots in a sample of 542,584 Tweets, collected before and after Japan's 2014 general election. Typical forms of bot activity include massive Retweeting and repeated posting of (nearly) the same message, sometimes used in combination. We focus on the second method and present (1) a case study on several patterns of bot activity, (2) methodological considerations on the automatic identification of such patterns and the prerequisite near-duplicate detection, and (3) we give qualitative insights into the purposes behind the usage of social/political bots. We argue that it was in the latency of the semi-public sphere of social mediaand not in the visible or manifest public sphere (official campaign platform, mass media)where Shinz Abe's hidden nationalist agenda interlocked and overlapped with the one propagated by organizations such as Nippon Kaigi and Internet right-wingers (netto uyo) during the election campaign, the latter potentially forming an enormous online support army of Abe's agenda.",,,,30,34,"MARY ANN LIEBERT, INC",NEW ROCHELLE,BIG DATA-US,10.1089/big.2017.0049,http://dx.doi.org/10.1089/big.2017.0049,"Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science,,52,schaefer (2017),4,evaluating impact of bots (politics),30
"Ferrara, E; Cresci, S; Luceri, L","Ferrara, Emilio; Cresci, Stefano; Luceri, Luca",2020,JOURNAL OF COMPUTATIONAL SOCIAL SCIENCE,English,Article,,Misinformation; Abuse; Social bots; Infodemics; Social media; COVID-19,SCIENCE; FIGHT,"Misinformation, manipulation, and abuse on social media in the era of COVID-19","The COVID-19 pandemic represented an unprecedented setting for the spread of online misinformation, manipulation, and abuse, with the potential to cause dramatic real-world consequences. The aim of this special issue was to collect contributions investigating issues such as the emergence of infodemics, misinformation, conspiracy theories, automation, and online harassment on the onset of the coronavirus outbreak. Articles in this collection adopt a diverse range of methods and techniques, and focus on the study of the narratives that fueled conspiracy theories, on the diffusion patterns of COVID-19 misinformation, on the global news sentiment, on hate speech and social bot interference, and on multimodal Chinese propaganda. The diversity of the methodological and scientific approaches undertaken in the aforementioned articles demonstrates the interdisciplinarity of these issues. In turn, these crucial endeavors might anticipate a growing trend of studies where diverse theories, models, and techniques will be combined to tackle the different aspects of online misinformation, manipulation, and abuse.",,,,31,32,SPRINGERNATURE,LONDON,J COMPUT SOC SCI,10.1007/s42001-020-00094-5,http://dx.doi.org/10.1007/s42001-020-00094-5,"Social Sciences, Mathematical Methods",Emerging Sources Citation Index (ESCI),Mathematical Methods In Social Sciences,,244,ferrara (2020),4,evaluating impact of bots (politics),31
"Ahmed, W; Lugovic, S","Ahmed, Wasim; Lugovic, Sergej",2019,ONLINE INFORMATION REVIEW,English,Article,,Twitter; Social media; Social network analysis; Fake news; Information diffusion; Bots,TWITTER,Social media analytics: analysis and visualisation of news diffusion using NodeXL,"Purpose The purpose of this paper is to provide an overview of NodeXL in the context of news diffusion. Journalists often include a social media dimension in their stories but lack the tools to get digital photos of the virtual crowds about which they write. NodeXL is an easy to use tool for collecting, analysing, visualising and reporting on the patterns found in collections of connections in streams of social media. With a network map patterns emerge that highlight key people, groups, divisions and bridges, themes and related resources. Design/methodology/approach This study conducts a literature review of previous empirical work which has utilised NodeXL and highlights the potential of NodeXL to provide network insights of virtual crowds during emerging news events. It then develops a number of guidelines which can be utilised by news media teams to measure and map information diffusion during emerging news events. Findings One emergent software application known as NodeXL has allowed journalists to take group photos of the connections among a group of users on social media. It was found that a diverse range of disciplines utilise NodeXL in academic research. Furthermore, based on the features of NodeXL, a number of guidelines were developed which provide insight into how to measure and map emerging news events on Twitter.",,,,33,34,EMERALD GROUP PUBLISHING LTD,BINGLEY,ONLINE INFORM REV,10.1108/OIR-03-2018-0093,http://dx.doi.org/10.1108/OIR-03-2018-0093,"Computer Science, Information Systems; Information Science & Library Science",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science; Information Science & Library Science,,290,ahmed (2019),4,detecting bots (general),33
"Bimber, B; de.Zuniga, HG","Bimber, Bruce; Gil de Zuniga, Homero",2020,NEW MEDIA & SOCIETY,English,Article,,Artificial intelligence; bot; computational propaganda; deepfake; machine learning; propaganda; public opinion; public sphere; social media army,POLITICAL COMMUNICATION; NEWS; DEMOCRACY; INTERNET; TWITTER; FALSE; TECHNOLOGIES; AFFORDANCES; KNOWLEDGE; MESSAGE,The unedited public sphere,"The health of democratic public spheres is challenged by the circulation of falsehoods. These epistemic problems are connected to social media and they raise a classic problem of how to understand the role of technology in political developments. We discuss three sets of technological affordances of social media that facilitate the spread of false beliefs: obscuring the provenance of information, facilitating deception about authorship, and providing for manipulation of social signals. We argue that these do not make social media a cause of problems with falsehoods, but explanations of epistemic problems should account for social media to understand the timing and widespread occurrence of epistemic problems. We argue that the marketplace of ideas cannot be adequate as a remedy for these problems, which require epistemic editing by the press.",,,,34,34,SAGE PUBLICATIONS LTD,LONDON,NEW MEDIA SOC,10.1177/1461444819893980,http://dx.doi.org/10.1177/1461444819893980,Communication,Social Science Citation Index (SSCI),Communication,,391,bimber (2020),4,evaluating impact of bots (politics),34
"Keller, FB; Schoch, D; Stier, S; Yang, J","Keller, Franziska B.; Schoch, David; Stier, Sebastian; Yang, JungHwan",2020,POLITICAL COMMUNICATION,English,Article,,disinformation; astroturfing; election campaign; propaganda; social media,SOCIAL MEDIA; ENGAGEMENT; NETWORKS; ELECTION; NEWS,Political Astroturfing on Twitter: How to Coordinate a Disinformation Campaign,"Political astroturfing, a centrally coordinated disinformation campaign in which participants pretend to be ordinary citizens acting independently, has the potential to influence electoral outcomes and other forms of political behavior. Yet, it is hard to evaluate the scope and effectiveness of political astroturfing without ground truth information, such as the verified identity of its agents and instigators. In this paper, we study the South Korean National Information Service's (NIS) disinformation campaign during the presidential election in 2012, taking advantage of a list of participating accounts published in court proceedings. Features that best distinguish these accounts from regular users in contemporaneously collected Twitter data are traces left by coordination among astroturfing agents, instead of the individual account characteristics typically used in related approaches such as social bot detection. We develop a methodology that exploits these distinct empirical patterns to identify additional likely astroturfing accounts and validate this detection strategy by analyzing their messages and current account status. However, an analysis relying on Twitter influence metrics shows that the known and suspect NIS accounts only had a limited impact on political social media discussions. By using the principal-agent framework to analyze one of the earliest revealed instances of political astroturfing, we improve on extant methodological approaches to detect disinformation campaigns and ground them more firmly in social science theory.",,,,60,62,TAYLOR & FRANCIS INC,PHILADELPHIA,POLIT COMMUN,10.1080/10584609.2019.1661888,http://dx.doi.org/10.1080/10584609.2019.1661888,Communication; Political Science,Social Science Citation Index (SSCI),Communication; Government & Law,,146,keller (2020),4,evaluating impact of bots (politics),60
"Chavoshi, N; Hamooni, H; Mueen, A","Chavoshi, Nikan; Hamooni, Hossein; Mueen, Abdullah",2017,WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB,English,Proceedings Paper,26th International Conference on World Wide Web (WWW),Time series mining; Pattern mining; Bot; Social Media,,Temporal Patterns in Bot Activities,"Correlated or synchronized bots commonly exist in social media sites such as Twitter. Bots work towards gaining human followers, participating in campaigns, and engaging in unethical activities such as spamming and false click generation. In this paper, we perform temporal pattern mining on bot activities in Twitter. We discover motifs (repeating behavior), discords (anomalous behavior), joins, bursts and dynamic clusters in activities of Twitter bots, and explain the significance of these temporal patterns in gaining competitive advantage over humans. Our analysis identifies a small set of indicators that separates bots from humans with high precision.",,,,20,20,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/3041021.3051114,http://dx.doi.org/10.1145/3041021.3051114,"Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,73,chavoshi (2017a),5,monitoring bots (general),20
"Badawy, A; Addawood, A; Lerman, K; Ferrara, E","Badawy, Adam; Addawood, Aseel; Lerman, Kristina; Ferrara, Emilio",2019,SOCIAL NETWORK ANALYSIS AND MINING,English,Article,,Social media manipulation; Russian trolls; Bots; Influence campaigns,SOCIAL MEDIA; POLITICS; TWITTER; DIFFUSION; FACEBOOK,Characterizing the 2016 Russian IRA influence campaign,"Until recently, social media were seen to promote democratic discourse on social and political issues. However, this powerful communication ecosystem has come under scrutiny for allowing hostile actors to exploit online discussions in an attempt to manipulate public opinion. A case in point is the ongoing U.S. Congress investigation of Russian interference in the 2016 U.S. election campaign, with Russia accused of, among other things, using trolls (malicious accounts created for the purpose of manipulation) and bots (automated accounts) to spread propaganda and politically biased information. In this study, we explore the effects of this manipulation campaign, taking a closer look at users who re-shared the posts produced on Twitter by the Russian troll accounts publicly disclosed by U.S. Congress investigation. We collected a dataset of 13 million election-related posts shared on Twitter in the year of 2016 by over a million distinct users. This dataset includes accounts associated with the identified Russian trolls as well as users sharing posts in the same time period on a variety of topics around the 2016 elections. We use label propagation to infer the users' ideology based on the news sources they share. We are able to classify a large number of the users as liberal or conservative with precision and recall above 84%. Conservative users who retweet Russian trolls produced significantly more tweets than liberal ones, about 8 times as many in terms of tweets. Additionally, trolls' position in the retweet network is stable overtime, unlike users who retweet them who form the core of the election-related retweet network by the end of 2016. Using state-of-the-art bot detection techniques, we estimate that about 5% and 11% of liberal and conservative users are bots, respectively. Text analysis on the content shared by trolls reveal that conservative trolls talk about refugees, terrorism, and Islam, while liberal trolls talk more about school shootings and the police. Although an ideologically broad swath of Twitter users were exposed to Russian trolls in the period leading up to the 2016 U.S. Presidential election, it is mainly conservatives who help amplify their message.",,,,21,21,SPRINGER WIEN,WIEN,SOC NETW ANAL MIN,10.1007/s13278-019-0578-6,http://dx.doi.org/10.1007/s13278-019-0578-6,"Computer Science, Information Systems",Emerging Sources Citation Index (ESCI),Computer Science,,53,badawy (2019b),5,monitoring bots (politics),21
"Grimme, C; Assenmacher, D; Adam, L","Grimme, Christian; Assenmacher, Dennis; Adam, Lena",2018,"SOCIAL COMPUTING AND SOCIAL MEDIA: USER EXPERIENCE AND BEHAVIOR, SCSM 2018, PT I",English,Proceedings Paper,10th International Conference on Social Computing and Social Media (SCSM) Held as Part of 20th International Conference on Human-Computer Interaction (HCI International),Social bots; Online propaganda; Social media analysis; Social media computation,,Changing Perspectives: Is It Sufficient to Detect Social Bots?,"The identification of automated activitiy in social media, specifically the detection of social bots, has become one of the major tasks within the field of social media computation. Recently published classification algorithms and frameworks focus on the identification of single bot accounts. Within different Twitter experiments, we show that these classifiers can be bypassed by hybrid approaches, which on a first glance may motivate further research for more sophisticated techniques. However, we pose the question, whether the detection of single bot accounts is a necessary condition for identifying malicious, strategic attacks on public opinion. Or is it more productive to concentrate on detecting strategies?",,,,23,23,SPRINGER INTERNATIONAL PUBLISHING AG,CHAM,LECT NOTES COMPUT SC,10.1007/978-3-319-91521-0_32,http://dx.doi.org/10.1007/978-3-319-91521-0_32,"Computer Science, Artificial Intelligence; Computer Science, Information Systems; Communication; Computer Science, Software Engineering; Computer Science, Theory & Methods; Social Issues",Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index- Social Science &amp; Humanities (CPCI-SSH),Computer Science; Communication; Social Issues,,60,grimme (2018),5,detecting bots (general),23
"Grimme, C; Preuss, M; Adam, L; Trautmann, H","Grimme, Christian; Preuss, Mike; Adam, Lena; Trautmann, Heike",2017,BIG DATA,English,Article,,hybridization; political big data; propaganda detection; social bots,,Social Bots: Human-Like by Means of Human Control?,"Social bots are currently regarded an influential but also somewhat mysterious factor in public discourse and opinion making. They are considered to be capable of massively distributing propaganda in social and online media, and their application is even suspected to be partly responsible for recent election results. Astonishingly, the term social bot is not well defined and different scientific disciplines use divergent definitions. This work starts with a balanced definition attempt, before providing an overview of how social bots actually work (taking the example of Twitter) and what their current technical limitations are. Despite recent research progress in Deep Learning and Big Data, there are many activities bots cannot handle well. We then discuss how bot capabilities can be extended and controlled by integrating humans into the process and reason that this is currently the most promising way to realize meaningful interactions with other humans. This finally leads to the conclusion that hybridization is a challenge for current detection mechanisms and has to be handled with more sophisticated approaches to identify political propaganda distributed with social bots.",,,,50,52,"MARY ANN LIEBERT, INC",NEW ROCHELLE,BIG DATA,10.1089/big.2017.0044,http://dx.doi.org/10.1089/big.2017.0044,"Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods",Science Citation Index Expanded (SCI-EXPANDED),Computer Science,,44,grimme (2017),5,detecting bots (politics),50
"Badawy, A; Ferrara, E; Lerman, K","Badawy, Adam; Ferrara, Emilio; Lerman, Kristina",2018,2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM),English,Proceedings Paper,IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),Social media manipulation; Russian trolls; Bots; Misinformation,SOCIAL MEDIA,Analyzing the Digital Traces of Political Manipulation: The 2016 Russian Interference Twitter Campaign,"Until recently, social media was seen to promote democratic discourse on social and political issues. However, this powerful communication platform has come under scrutiny for allowing hostile actors to exploit online discussions in an attempt to manipulate public opinion. A case in point is the ongoing U.S. Congress investigation of Russian interference in the 2016 U.S. election campaign, with Russia accused of, among other things, using trolls (malicious accounts created for the purpose of manipulation) and bots (automated accounts) to spread misinformation and politically biased information. In this study, we explore the effects of this manipulation campaign, taking a closer look at users who re-shared the posts produced on Twitter by the Russian troll accounts publicly disclosed by U.S. Congress investigation. We collected a dataset with over 43 million elections-related posts shared on Twitter between September 16 and November 9, 2016 by about 5.7 million distinct users. This dataset includes accounts associated with the identified Russian trolls. We use label propagation to infer the users' ideology based on the news sources they shared, to classify a large number of them as liberal or conservative with precision and recall above 90%. Conservatives retweeted Russian trolls significantly more often than liberals and produced 36 times more tweets. Additionally, most of the troll content originated in, and was shared by users from Southern states. Using state-of-the-art bot detection techniques, we estimated that about 4.9% and 6.2% of liberal and conservative users respectively were bots. Text analysis on the content shared by trolls reveals that they had a mostly conservative, pro-Trump agenda. Although an ideologically broad swath of Twitter users were exposed to Russian trolls in the period leading up to the 2016 U.S. Presidential election, it was mainly conservatives who helped amplify their message.",,,,88,88,IEEE,NEW YORK,,,,"Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science; Engineering,,50,badawy (2018),5,evaluating impact of bots (politics),88
"Kudugunta, S; Ferrara, E","Kudugunta, Sneha; Ferrara, Emilio",2018,INFORMATION SCIENCES,English,Article,,Social media networks; Web and social media; Social bots; Deep learning; Deep neural networks,SOCIAL MEDIA,Deep neural networks for bot detection,"The problem of detecting bots, automated social media accounts governed by software but disguising as human users, has strong implications. For example, bots have been used to sway political elections by distorting online discourse, to manipulate the stock market, or to push anti-vaccine conspiracy theories that may have caused health epidemics. Most techniques proposed to date detect bots at the account level, by processing large amounts of social media posts, and leveraging information from network structure, temporal dynamics, sentiment analysis, etc. In this paper, we propose a deep neural network based on contextual long short-term memory (LSTM) architecture that exploits both content and metadata to detect bots at the tweet level: contextual features are extracted from user metadata and fed as auxiliary input to LSTM deep nets processing the tweet text. Another contribution that we make is proposing a technique based on synthetic minority oversampling to generate a large labeled dataset, suitable for deep nets training, from a minimal amount of labeled data (roughly 3000 examples of sophisticated Twitter hots). We demonstrate that, from just one single tweet, our architecture can achieve high classification accuracy (AUC > 96%) in separating bots from humans. We apply the same architecture to account-level bot detection, achieving nearly perfect classification accuracy (AUC > 99%). Our system outperforms previous state of the art while leveraging a small and interpretable set of features, yet requiring minimal training data. (C) 2018 Elsevier Inc. All rights reserved.",,,,124,128,ELSEVIER SCIENCE INC,NEW YORK,INFORM SCIENCES,10.1016/j.ins.2018.08.019,http://dx.doi.org/10.1016/j.ins.2018.08.019,"Computer Science, Information Systems",Science Citation Index Expanded (SCI-EXPANDED),Computer Science,,41,kudugunta (2018),5,detecting bots (general),124
"Bastos, MT; Mercea, D","Bastos, Marco T.; Mercea, Dan",2019,SOCIAL SCIENCE COMPUTER REVIEW,English,Article,,Brexit; Twitter; fake news; sock puppets; retweets cascades; political bots,POLITICS,The Brexit Botnet and User-Generated Hyperpartisan News,"In this article, we uncover a network of Twitterbots comprising 13,493 accounts that tweeted the United Kingdom European Union membership referendum, only to disappear from Twitter shortly after the ballot. We compare active users to this set of political bots with respect to temporal tweeting behavior, the size and speed of retweet cascades, and the composition of their retweet cascades (user-to-bot vs. bot-to-bot) to evidence strategies for bot deployment. Our results move forward the analysis of political bots by showing that Twitterbots can be effective at rapidly generating small- to medium-sized cascades; that the retweeted content comprises user-generated hyperpartisan news, which is not strictly fake news, but whose shelf life is remarkably short; and, finally, that a botnet may be organized in specialized tiers or clusters dedicated to replicating either active users or content generated by other bots.",,,,128,130,SAGE PUBLICATIONS INC,THOUSAND OAKS,SOC SCI COMPUT REV,10.1177/0894439317734157,http://dx.doi.org/10.1177/0894439317734157,"Computer Science, Interdisciplinary Applications; Information Science & Library Science; Social Sciences, Interdisciplinary",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science; Information Science & Library Science; Social Sciences - Other Topics,,117,bastos (2019),5,detecting bots (politics),128
"Davis, CA; Varol, O; Ferrara, E; Flammini, A; Menczer, F","Davis, Clayton A.; Varol, Onur; Ferrara, Emilio; Flammini, Alessandro; Menczer, Filippo",2016,PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION),English,Proceedings Paper,25th International Conference on World Wide Web (WWW),social bot; sybil account; social media,,BotOrNot: A System to Evaluate Social Bots,"While most online social media accounts are controlled by humans, these platforms also host automated agents called social bots or sybil accounts. Recent literature reported on cases of social bots imitating humans to manipulate discussions, alter the popularity of users, pollute content and spread misinformation, and even perform terrorist propaganda and recruitment actions. Here we present BotOrNot, a publicly-available service that leverages more than one thousand features to evaluate the extent to which a Twitter account exhibits similarity to the known characteristics of social bots. Since its release in May 2014, BotOrNot has served over one million requests via our website and APIs.",,,,309,310,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/2872518.2889302,http://dx.doi.org/10.1145/2872518.2889302,"Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,61,davis (2016),5,detecting bots (politics),309
"Wang, P; Angarita, R; Renna, I","Wang, Patrick; Angarita, Rafael; Renna, Ilaria",2018,COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018),English,Proceedings Paper,27th World Wide Web (WWW) Conference,Social bots; Social media; Deceptive information; Semantic Web,MEDIA,Is this the Era of Misinformation yet? Combining Social Bots and Fake News to Deceive the Masses,"Social media is an amazing platform for enhancing public exposure. Anyone, even social bots, can reach out to a vast community and expose one's opinion. But what happens when fake news is (un)intentionally spread within a social media? This paper reviews techniques that can be used to fabricate fake news and depicts a scenario where social bots evolve in a fully semantic Web to infest social media with automatically generated deceptive information.",,,,20,21,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/3184558.3191610,http://dx.doi.org/10.1145/3184558.3191610,"Computer Science, Artificial Intelligence; Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,63,wang (2018),6,evaluating impact of bots (politics),20
"Savage, S; Monroy-Hernandez, A; Hollerer, T","Savage, Saiph; Monroy-Hernandez, Andres; Hoellerer, Tobias",2016,ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016),English,Proceedings Paper,19th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW),bots; volunteers; activism; micro-contributions; social media,,Botivist: Calling Volunteers to Action using Online Bots,"To help activists call new volunteers to action, we present Botivist: a platform that uses Twitter bots to find potential volunteers and request contributions. By leveraging different Twitter accounts, Botivist employs different strategies to encourage participation. We explore how people respond to bots calling them to action using a test case about corruption in Latin America. Our results show that the majority of volunteers (> 80%) who responded to Botivist's calls to action contributed relevant proposals to address the assigned social problem. Different strategies produced differences in the quantity and relevance of contributions. Some strategies that work well offline and face-to-face appeared to hinder people's participation when used by an online bot. We analyze user behavior in response to being approached by bots with an activist purpose. We also provide strong evidence for the value of this type of civic media, and derive design implications.",,,,25,25,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/2818048.2819985,http://dx.doi.org/10.1145/2818048.2819985,"Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science,,88,savage (2016),6,monitoring bots (politics),25
"Roy, KC; Hasan, S; Sadri, AM; Cebrian, M","Roy, Kamol Chandra; Hasan, Samiul; Sadri, Arif Mohaimin; Cebrian, Manuel",2020,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,English,Article,,Crisis communication; Hurricane warning; Evacuation; Social media; Twitter; Hurricane Sandy; Disaster management,RISK COMMUNICATION; TIME-SERIES; MODEL; ANALYTICS,Understanding the efficiency of social media based crisis communication during hurricane Sandy,"Rapid communication during extreme events is one of the critical aspects of successful disaster management strategies. Due to their ubiquitous nature, social media platforms are expected to offer a unique opportunity for crisis communication. In this study, about 52.5 million tweets related to hurricane Sandy posted by 13.75 million users are analyzed to assess the effectiveness of social media communication during disasters and identify the contributing factors leading to effective crisis communication strategies. Efficiency of a social media user is defined as the ratio of attention gained over the number of tweets posted. A model is developed to identify more efficient users based on several relevant features. Results indicate that during a disaster event, only few social media users become highly efficient in gaining attention. In addition, efficiency does not depend on the frequency of tweeting activity only; instead it depends on the number of followers and friends, user category, bot score (controlled by a human or a machine), and activity patterns (predictability of activity frequency). Since the proposed efficiency metric is easy to evaluate, it can potentially detect effective social media users in real time to communicate information and awareness to vulnerable communities during a disaster.",,,,31,31,ELSEVIER SCI LTD,OXFORD,INT J INFORM MANAGE,10.1016/j.ijinfomgt.2019.102060,http://dx.doi.org/10.1016/j.ijinfomgt.2019.102060,Information Science & Library Science,Social Science Citation Index (SSCI),Information Science & Library Science,,265,roy (2020),6,evaluating impact of bots (politics),31
"Gorwa, R; Guilbeault, D","Gorwa, Robert; Guilbeault, Douglas",2020,POLICY AND INTERNET,English,Article,,social media bots; algorithms; political automation; political propaganda; public policy; democracy; Twitter; Facebook,COMMUNICATION; NEWS,Unpacking the Social Media Bot: A Typology to Guide Research and Policy,"Amid widespread reports of digital influence operations during major elections, policymakers, scholars, and journalists have become increasingly interested in the political impact of social media bots. Most recently, platform companies like Facebook and Twitter have been summoned to testify about bots as part of investigations into digitally enabled foreign manipulation during the 2016 U.S. Presidential election. Facing mounting pressure from both the public and from legislators, these companies have been instructed to crack down on apparently malicious bot accounts. But as this article demonstrates, since the earliest writings on bots in the 1990s, there has been substantial confusion as to exactly what a bot is and what it does. We argue that multiple forms of ambiguity are responsible for much of the complexity underlying contemporary bot-related policy, and that before successful policy interventions can be formulated, a more comprehensive understanding of bots-especially how they are defined and measured-will be needed. In this article, we provide a typology of different types of bots, provide clear guidelines for better categorizing political automation, and unpack the impact that it can have on contemporary technology policy. We conclude by outlining the main challenges and ambiguities that will face both researchers and legislators as they tackle bots in the future.",,,,44,48,WILEY,HOBOKEN,POLICY INTERNET,10.1002/poi3.184,http://dx.doi.org/10.1002/poi3.184,Communication; Political Science,Social Science Citation Index (SSCI),Communication; Government & Law,,4,gorwa (2020),6,detecting bots (politics),44
"Ross, B; Pilz, L; Cabrera, B; Brachten, F; Neubaum, G; Stieglitz, S","Ross, Bjoern; Pilz, Laura; Cabrera, Benjamin; Brachten, Florian; Neubaum, German; Stieglitz, Stefan",2019,EUROPEAN JOURNAL OF INFORMATION SYSTEMS,English,Article,,Spiral of silence; agent-based modelling; social bots; simulation; network analysis,PUBLIC-OPINION; COLLECTIVE DYNAMICS; MEDIA NETWORKS; SELF-CENSOR; BIG DATA; ONLINE; WILLINGNESS; INFORMATION; PERCEPTIONS; ANALYTICS,Are social bots a real threat? An agent-based model of the spiral of silence to analyse the impact of manipulative actors in social networks,"Information systems such as social media strongly influence public opinion formation. Additionally, communication on the internet is shaped by individuals and organisations with various aims. This environment has given rise to phenomena such as manipulated content, fake news, and social bots. To examine the influence of manipulated opinions, we draw on the spiral of silence theory and complex adaptive systems. We translate empirical evidence of individual behaviour into an agent-based model and show that the model results in the emergence of a consensus on the collective level. In contrast to most previous approaches, this model explicitly represents interactions as a network. The most central actor in the network determines the final consensus 60-70% of the time. We then use the model to examine the influence of manipulative actors such as social bots on public opinion formation. The results indicate that, in a highly polarised setting, depending on their network position and the overall network density, bot participation by as little as 2-4% of a communication network can be sufficient to tip over the opinion climate in two out of three cases. These findings demonstrate a mechanism by which bots could shape the norms adopted by social media users.",,,,53,57,TAYLOR & FRANCIS LTD,ABINGDON,EUR J INFORM SYST,10.1080/0960085X.2018.1560920,http://dx.doi.org/10.1080/0960085X.2018.1560920,"Computer Science, Information Systems; Information Science & Library Science; Management",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science; Information Science & Library Science; Business & Economics,,198,ross (2019),6,detecting bots (politics),53
"Abokhodair, N; Yoo, D; McDonald, DW","Abokhodair, Norah; Yoo, Daisy; McDonald, David W.",2015,PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15),English,Proceedings Paper,ACM International Conference on Computer-Supported Cooperative Work and Social Computing (CSCW),Bots; Botnet; Automated Social Actor; Twitter; Social Computing; Arab Spring,BOTS,"Dissecting a Social Botnet: Growth, Content and Influence in Twitter","Social botnets have become an important phenomenon on social media. There are many ways in which social bots can disrupt or influence online discourse, such as, spam hashtags, scam twitter users, and astroturfing. In this paper we considered one specific social botnet in Twitter to understand how it grows over time, how the content of tweets by the social botnet differ from regular users in the same dataset, and lastly, how the social botnet may have influenced the relevant discussions. Our analysis is based on a qualitative coding for approximately 3000 tweets in Arabic and English from the Syrian social bot that was active for 35 weeks on Twitter before it was shutdown. We find that the growth, behavior and content of this particular botnet did not specifically align with common conceptions of botnets. Further we identify interesting aspects of the botnet that distinguish it from regular users.",,,,100,101,ASSOC COMPUTING MACHINERY,NEW YORK,,10.1145/2675133.2675208,http://dx.doi.org/10.1145/2675133.2675208,"Computer Science, Theory & Methods; Engineering, Electrical & Electronic",Conference Proceedings Citation Index - Science (CPCI-S),Computer Science; Engineering,,219,abokhodair (2015),6,monitoring bots (general),100
"Ciechanowski, L; Przegalinska, A; Magnuski, M; Gloor, P","Ciechanowski, Leon; Przegalinska, Aleksandra; Magnuski, Mikolaj; Gloor, Peter",2019,FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE,English,Article,,Human-computer interaction; Chatbots; Affective computing; Psychophysiology; Uncanny valley,SOCIAL-INTERACTION; VALENCE,In the shades of the uncanny valley: An experimental study of human-chatbot interaction,"This project has been carried out in the context of recent major developments in botics and more widespread usage of virtual agents in personal and professional sphere. The general purpose of the experiment was to thoroughly examine the character of the human-non-human interaction process. Thus, in the paper, we present a study of human-chatbot interaction, focusing on the affective responses of users to different types of interfaces with which they interact. The experiment consisted of two parts: measurement of psychophysiological reactions of chatbot users and a detailed questionnaire that focused on assessing interactions and willingness to collaborate with a bot. In the first quantitative stage, participants interacted with a chatbot, either with a simple text chatbot (control group) or an avatar reading its responses in addition to only presenting them on the screen (experimental group. We gathered the following psychophysiological data from participants: electromyography (EMG), respirometer (RSP), electrocardiography (ECG), and electrodermal activity (EDA). In the last, declarative stage, participants filled out a series of questionnaires related to the experience of interacting with (chat)bots and to the overall human-(chat)bot collaboration assessment. The theory of planned behaviour survey investigated attitude towards cooperation with chatbots in the future. The social presence survey checked how much the chatbot was considered to be a real person. The anthropomorphism scale measured the extent to which the chatbot seems humanlike. Our particular focus was on the so-called uncanny valley effect, consisting of the feeling of eeriness and discomfort towards a given medium or technology that frequently appears in various kinds of human-machine interactions. Our results show that participants were experiencing lesser uncanny effects and less negative affect in cooperation with a simpler text chatbot than with the more complex, animated avatar chatbot. The simple chatbot have also induced less intense psychophysiological reactions. Despite major developments in botics, the user's affective responses towards bots have frequently been neglected. In our view, understanding the user's side may be crucial for designing better chatbots in the future and, thus, can contribute to advancing the field of human-computer interaction. (C) 2018 Elsevier B.V. All rights reserved.",,,,120,120,ELSEVIER SCIENCE BV,AMSTERDAM,FUTURE GENER COMP SY,10.1016/j.future.2018.01.055,http://dx.doi.org/10.1016/j.future.2018.01.055,"Computer Science, Theory & Methods",Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI),Computer Science,,329,ciechanowski (2019),6,evaluating impact of bots (general),120
"Ford, H; Hutchinson, J","Ford, Heather; Hutchinson, Jonathon",2019,DIGITAL JOURNALISM,English,Article,,Newsbots; automated media; conversational journalism; public service media; algorithmic journalism,PUBLIC-SERVICE MEDIA; STRATEGIES,Newsbots That Mediate Journalist and Audience Relationships,"News media organisations are experimenting with a new generation of newsbots that move beyond automated headline delivery to the delivery of news according to a conversational format within the context of private messaging services. To build the newsbot, journalists craft statements and answers to users' questions that mimic a natural conversation between a journalist and user. In so doing, journalists are experimenting with styles of communication that reflect very particular journalistic personas. We investigate the persona of the news chatbot created by the Australian Broadcasting Corporation (ABC), the better to understand how the public broadcaster's forays into social media service delivery and automation are shaping new relationships between public service broadcasters and their audiences. We find that, for a section of the audience that uses it, the friendly newsbot contrasts favourably with their previous experience with news and the journalists who produce it. The public service journalists who operate the bot are, in turn, using the bot to try to reach new audiences by experimenting with a more informal, intimate relationship with citizen users. The supposedly intelligent (but in actual fact very much human-crafted) newsbot is the vehicle through which this new relationship is being forged.",,,,24,25,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD",ABINGDON,DIGIT JOURNAL,10.1080/21670811.2019.1626752,http://dx.doi.org/10.1080/21670811.2019.1626752,Communication,Social Science Citation Index (SSCI),Communication,,280,ford (2019),7,detecting bots (general),24
"Mittelstadt, B","Mittelstadt, Brent",2016,INTERNATIONAL JOURNAL OF COMMUNICATION,English,Article,,algorithms; transparency; information ethics; automation; politics; ethics; personalization; recommendation systems; bots,ALGORITHMS; ETHICS,Auditing for Transparency in Content Personalization Systems,"Do we have a right to transparency when we use content personalization systems? Building on prior work in discrimination detection in data mining, I propose algorithm auditing as a compatible ethical duty for providers of content personalization systems to maintain the transparency of political discourse. I explore barriers to auditing that reveal the practical limitations on the ethical duties of service providers. Content personalization systems can function opaquely and resist auditing. However, the belief that highly complex algorithms, such as bots using machine learning, are incomprehensible to human users should not be an excuse to surrender high quality political discourse. Auditing is recommended as a way to map and redress algorithmic political exclusion in practice. However, the opacity of algorithmic decision making poses a significant challenge to the implementation of auditing.",,,,25,25,USC ANNENBERG PRESS,LOS ANGELES,INT J COMMUN-US,,,Communication,Social Science Citation Index (SSCI),Communication,,344,mittelstadt (2016),7,evaluating impact of bots (politics),25
"Hasler, BS; Tuchman, P; Friedman, D","Hasler, Beatrice S.; Tuchman, Peleg; Friedman, Doron",2013,COMPUTERS IN HUMAN BEHAVIOR,English,Article,,Social virtual worlds; Automated data collection; Survey interviewing; Bots; Avatars; Media equation,SOCIAL RESPONSES; BEHAVIOR; COMPUTERS; POLITE; STYLE; TIME; WEB,Virtual research assistants: Replacing human interviewers by automated avatars in virtual worlds,"We conducted an experiment to evaluate the use of embodied survey bots (i.e., software-controlled avatars) as a novel method for automated data collection in 3D virtual worlds. A bot and a human-controlled avatar carried out a survey interview within the virtual world, Second Life, asking participants about their religion. In addition to interviewer agency (bot vs. human), we tested participants' virtual age, that is, the time passed since the person behind the avatar joined Second Life, as a predictor for response rate and quality. The human interviewer achieved a higher response rate than the bot Participants with younger avatars were more willing to disclose information about their real life than those with older avatars. Surprisingly, the human interviewer received more negative responses than the bot. Affective reactions of older avatars were also more negative than those of younger avatars. The findings provide support for the utility of bots as virtual research assistants but raise ethical questions that need to be considered carefully. (C) 2013 Elsevier Ltd. All rights reserved.",,,,30,30,PERGAMON-ELSEVIER SCIENCE LTD,OXFORD,COMPUT HUM BEHAV,10.1016/j.chb.2013.01.004,http://dx.doi.org/10.1016/j.chb.2013.01.004,"Psychology, Multidisciplinary; Psychology, Experimental",Social Science Citation Index (SSCI),Psychology,,334,hasler (2013),7,avaliando impacto de bots,30
"Yuan, XY; Schuchard, RJ; Crooks, AT","Yuan, Xiaoyi; Schuchard, Ross J.; Crooks, Andrew T.",2019,SOCIAL MEDIA + SOCIETY,English,Article,,anti-vaccine movement; Twitter; social media; opinion classification; bot analysis,REFUSAL; HESITANCY; KNOWLEDGE; INFORMATION; MOVEMENT,Examining Emergent Communities and Social Bots Within the Polarized Online Vaccination Debate in Twitter,"Many states in the United States allow a belief exemption for measles, mumps, and rubella (MMR) vaccines. People's opinion on whether or not to take the vaccine can have direct consequences in public health. Social media has been one of the dominant communication channels for people to express their opinions of vaccination. Despite governmental organizations' efforts of disseminating information of vaccination benefits, anti-vaccine sentiment is still gaining momentum. Studies have shown that bots on social media (i.e., social bots) can influence opinion trends by posting a substantial number of automated messages. The research presented here investigates the communication patterns of anti- and pro-vaccine users and the role of bots in Twitter by studying a retweet network related to MMR vaccine after the 2015 California Disneyland measles outbreak. We first classified the users into anti-vaccination, neutral to vaccination, and pro-vaccination groups using supervised machine learning. We discovered that pro- and anti-vaccine users retweet predominantly from their own opinion group. In addition, our bot analysis discovers that 1.45% of the corpus users were identified as likely bots which produced 4.59% of all tweets within our dataset. We further found that bots display hyper-social tendencies by initiating retweets at higher frequencies with users within the same opinion group. The article concludes that highly clustered anti-vaccine Twitter users make it difficult for health organizations to penetrate and counter opinionated information while social bots may be deepening this trend. We believe that these findings can be useful in developing strategies for health communication of vaccination.",,,,37,37,SAGE PUBLICATIONS LTD,LONDON,SOC MEDIA SOC,10.1177/2056305119865465,http://dx.doi.org/10.1177/2056305119865465,Communication,Social Science Citation Index (SSCI),Communication,,86,yuan (2019),7,monitoring bots (politics),37
"Woolley, SC; Howard, PN","Woolley, Samuel C.; Howard, Philip N.",2016,INTERNATIONAL JOURNAL OF COMMUNICATION,English,Article,,political communication; science and technology studies; research trends; bots; algorithms; automation; social media; Internet of things,MEDIA,"Political Communication, Computational Propaganda, and Autonomous Agents","The Internet certainly disrupted our understanding of what communication can be, who does it, how, and to what effect. What constitutes the Internet has always been an evolving suite of technologies and a dynamic set of social norms, rules, and patterns of use. But the shape and character of digital communications are shifting again-the browser is no longer the primary means by which most people encounter information infrastructure. The bulk of digital communications are no longer between people but between devices, about people, over the Internet of things. Political actors make use of technological proxies in the form of proprietary algorithms and semiautomated social actors-political bots-in subtle attempts to manipulate public opinion. These tools are scaffolding for human control, but the way they work to afford such control over interaction and organization can be unpredictable, even to those who build them. So to understand contemporary political communication-and modern communication broadly-we must now investigate the politics of algorithms and automation.",,,,73,75,USC ANNENBERG PRESS,LOS ANGELES,INT J COMMUN-US,,,Communication,Social Science Citation Index (SSCI),Communication,,89,woolley (2016),7,evaluating impact of bots (politics),73
"Edwards, C; Edwards, A; Spence, PR; Shelton, AK","Edwards, Chad; Edwards, Autumn; Spence, Patric R.; Shelton, Ashleigh K.",2014,COMPUTERS IN HUMAN BEHAVIOR,English,Article,,Bot; Twitter; CASA; Credibility; Communication competence; Attraction,CREDIBILITY; COMPUTERS; RESPONSES; INFORMATION,Is that a bot running the social media feed? Testing the differences in perceptions of communication quality for a human agent and a bot agent on Twitter,"Due to the growth and popularity of Twitter, automated programs that can tweet are increasingly developed and employed. In line with the Computers Are Social Actors (CASA) paradigm (Reeves & Nass, 1996), findings suggest that Twitterbots are perceived as credible, attractive, competent in communication, and interactional. Additionally, there were no differences in the perceptions of source credibility, communication competence, or interactional intentions between the hot and human Twitter agents. However, the source of the human Twitter agent was rated higher in attraction (social and task) than was the Twitter-bot Results are discussed in light of CASA. Implications for organizations that might employ Twitterbots are also addressed. (C) 2013 Elsevier Ltd. All rights reserved.",,,,122,122,PERGAMON-ELSEVIER SCIENCE LTD,OXFORD,COMPUT HUM BEHAV,10.1016/j.chb.2013.08.013,http://dx.doi.org/10.1016/j.chb.2013.08.013,"Psychology, Multidisciplinary; Psychology, Experimental",Social Science Citation Index (SSCI),Psychology,,340,edwards (2014),7,evaluating impact of bots (politics),122